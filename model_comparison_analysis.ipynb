{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Model Comparison Analysis: Astra vs Qwen\n",
    "\n",
    "This notebook analyzes the performance of two AI models (Astra and Qwen) against human-labeled ground truth data (DB).\n",
    "\n",
    "## Categories Analyzed:\n",
    "1. **Equipment Presence** (Boolean)\n",
    "2. **Co-Manufacturing Status** (Boolean)\n",
    "3. **Food & Beverage Status** (Boolean)\n",
    "4. **Specialty Classification** (Multi-class exact match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('Copy of False positive comparison - no_prompt_combined.csv')\n",
    "\n",
    "print(f\"Total Records: {len(df)}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df, db_col, model_col, is_specialty=False):\n",
    "    \"\"\"\n",
    "    Calculate accuracy, precision, and confusion matrix metrics\n",
    "    \"\"\"\n",
    "    if is_specialty:\n",
    "        # Exact match for specialty\n",
    "        correct = (df[db_col] == df[model_col]).sum()\n",
    "        total = len(df)\n",
    "        accuracy = correct / total * 100\n",
    "        errors = total - correct\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': accuracy,\n",
    "            'correct': correct,\n",
    "            'total': total,\n",
    "            'errors': errors\n",
    "        }\n",
    "    else:\n",
    "        # Boolean fields\n",
    "        db_vals = df[db_col].astype(str).str.lower()\n",
    "        model_vals = df[model_col].astype(str).str.lower()\n",
    "        \n",
    "        db_bool = db_vals.isin(['true', 'yes', '1'])\n",
    "        model_bool = model_vals.isin(['true', 'yes', '1'])\n",
    "        \n",
    "        tp = ((db_bool == True) & (model_bool == True)).sum()\n",
    "        tn = ((db_bool == False) & (model_bool == False)).sum()\n",
    "        fp = ((db_bool == False) & (model_bool == True)).sum()\n",
    "        fn = ((db_bool == True) & (model_bool == False)).sum()\n",
    "        \n",
    "        total = len(df)\n",
    "        accuracy = (tp + tn) / total * 100\n",
    "        precision = tp / (tp + fp) * 100 if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) * 100 if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'tp': tp,\n",
    "            'tn': tn,\n",
    "            'fp': fp,\n",
    "            'fn': fn,\n",
    "            'total': total\n",
    "        }\n",
    "\n",
    "def plot_confusion_matrix(tp, tn, fp, fn, title):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix\n",
    "    \"\"\"\n",
    "    cm = np.array([[tp, fn], [fp, tn]])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Predicted Positive', 'Predicted Negative'],\n",
    "                yticklabels=['Actual Positive', 'Actual Negative'],\n",
    "                ax=ax, cbar_kws={'label': 'Count'})\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze Each Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Equipment Presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equipment analysis\n",
    "astra_equip = calculate_metrics(df, 'db_has_equipments', 'astra_has_equipments')\n",
    "qwen_equip = calculate_metrics(df, 'db_has_equipments', 'qwen_has_equipments')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"EQUIPMENT PRESENCE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nASTRA:\")\n",
    "print(f\"  Accuracy: {astra_equip['accuracy']:.2f}%\")\n",
    "print(f\"  Precision: {astra_equip['precision']:.2f}%\")\n",
    "print(f\"  False Positives: {astra_equip['fp']}\")\n",
    "print(f\"  False Negatives: {astra_equip['fn']}\")\n",
    "\n",
    "print(f\"\\nQWEN:\")\n",
    "print(f\"  Accuracy: {qwen_equip['accuracy']:.2f}%\")\n",
    "print(f\"  Precision: {qwen_equip['precision']:.2f}%\")\n",
    "print(f\"  False Positives: {qwen_equip['fp']}\")\n",
    "print(f\"  False Negatives: {qwen_equip['fn']}\")\n",
    "\n",
    "# Plot confusion matrices\n",
    "fig1 = plot_confusion_matrix(astra_equip['tp'], astra_equip['tn'], \n",
    "                              astra_equip['fp'], astra_equip['fn'], \n",
    "                              'ASTRA - Equipment Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "fig2 = plot_confusion_matrix(qwen_equip['tp'], qwen_equip['tn'], \n",
    "                              qwen_equip['fp'], qwen_equip['fn'], \n",
    "                              'QWEN - Equipment Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Co-Manufacturing Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co-manufacturing analysis\n",
    "astra_coman = calculate_metrics(df, 'db_is_coman', 'astra_is_coman')\n",
    "qwen_coman = calculate_metrics(df, 'db_is_coman', 'qwen_is_coman')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CO-MANUFACTURING STATUS ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nASTRA:\")\n",
    "print(f\"  Accuracy: {astra_coman['accuracy']:.2f}%\")\n",
    "print(f\"  Precision: {astra_coman['precision']:.2f}%\")\n",
    "print(f\"  False Positives: {astra_coman['fp']}\")\n",
    "print(f\"  False Negatives: {astra_coman['fn']}\")\n",
    "\n",
    "print(f\"\\nQWEN:\")\n",
    "print(f\"  Accuracy: {qwen_coman['accuracy']:.2f}%\")\n",
    "print(f\"  Precision: {qwen_coman['precision']:.2f}%\")\n",
    "print(f\"  False Positives: {qwen_coman['fp']}\")\n",
    "print(f\"  False Negatives: {qwen_coman['fn']}\")\n",
    "\n",
    "# Plot confusion matrices\n",
    "fig3 = plot_confusion_matrix(astra_coman['tp'], astra_coman['tn'], \n",
    "                              astra_coman['fp'], astra_coman['fn'], \n",
    "                              'ASTRA - Co-Manufacturing Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "fig4 = plot_confusion_matrix(qwen_coman['tp'], qwen_coman['tn'], \n",
    "                              qwen_coman['fp'], qwen_coman['fn'], \n",
    "                              'QWEN - Co-Manufacturing Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Food & Beverage Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Food & Beverage analysis\n",
    "astra_fb = calculate_metrics(df, 'db_is_food_beverage', 'astra_is_food_beverage')\n",
    "qwen_fb = calculate_metrics(df, 'db_is_food_beverage', 'qwen_is_food_beverage')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FOOD & BEVERAGE STATUS ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nASTRA:\")\n",
    "print(f\"  Accuracy: {astra_fb['accuracy']:.2f}%\")\n",
    "print(f\"  Precision: {astra_fb['precision']:.2f}%\")\n",
    "print(f\"  False Positives: {astra_fb['fp']}\")\n",
    "print(f\"  False Negatives: {astra_fb['fn']}\")\n",
    "\n",
    "print(f\"\\nQWEN:\")\n",
    "print(f\"  Accuracy: {qwen_fb['accuracy']:.2f}%\")\n",
    "print(f\"  Precision: {qwen_fb['precision']:.2f}%\")\n",
    "print(f\"  False Positives: {qwen_fb['fp']}\")\n",
    "print(f\"  False Negatives: {qwen_fb['fn']}\")\n",
    "\n",
    "# Plot confusion matrices\n",
    "fig5 = plot_confusion_matrix(astra_fb['tp'], astra_fb['tn'], \n",
    "                              astra_fb['fp'], astra_fb['fn'], \n",
    "                              'ASTRA - Food & Beverage Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "fig6 = plot_confusion_matrix(qwen_fb['tp'], qwen_fb['tn'], \n",
    "                              qwen_fb['fp'], qwen_fb['fn'], \n",
    "                              'QWEN - Food & Beverage Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Specialty Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specialty analysis\n",
    "astra_spec = calculate_metrics(df, 'db_specialty', 'astra_specialty', is_specialty=True)\n",
    "qwen_spec = calculate_metrics(df, 'db_specialty', 'qwen_specialty', is_specialty=True)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SPECIALTY CLASSIFICATION ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nASTRA:\")\n",
    "print(f\"  Accuracy: {astra_spec['accuracy']:.2f}%\")\n",
    "print(f\"  Correct: {astra_spec['correct']}/{astra_spec['total']}\")\n",
    "print(f\"  Errors: {astra_spec['errors']}\")\n",
    "\n",
    "print(f\"\\nQWEN:\")\n",
    "print(f\"  Accuracy: {qwen_spec['accuracy']:.2f}%\")\n",
    "print(f\"  Correct: {qwen_spec['correct']}/{qwen_spec['total']}\")\n",
    "print(f\"  Errors: {qwen_spec['errors']}\")\n",
    "\n",
    "# Show distribution of specialty values\n",
    "print(\"\\nSpecialty Value Distribution (DB):\")\n",
    "print(df['db_specialty'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparative Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy comparison across all categories\n",
    "categories = ['Equipment', 'Co-Manufacturing', 'Food & Beverage', 'Specialty']\n",
    "astra_accuracies = [\n",
    "    astra_equip['accuracy'], \n",
    "    astra_coman['accuracy'], \n",
    "    astra_fb['accuracy'], \n",
    "    astra_spec['accuracy']\n",
    "]\n",
    "qwen_accuracies = [\n",
    "    qwen_equip['accuracy'], \n",
    "    qwen_coman['accuracy'], \n",
    "    qwen_fb['accuracy'], \n",
    "    qwen_spec['accuracy']\n",
    "]\n",
    "\n",
    "x = np.arange(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bars1 = ax.bar(x - width/2, astra_accuracies, width, label='ASTRA', color='#3498db')\n",
    "bars2 = ax.bar(x + width/2, qwen_accuracies, width, label='QWEN', color='#e74c3c')\n",
    "\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Model Accuracy Comparison Across Categories', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1f}%',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision comparison for boolean categories\n",
    "bool_categories = ['Equipment', 'Co-Manufacturing', 'Food & Beverage']\n",
    "astra_precisions = [\n",
    "    astra_equip['precision'], \n",
    "    astra_coman['precision'], \n",
    "    astra_fb['precision']\n",
    "]\n",
    "qwen_precisions = [\n",
    "    qwen_equip['precision'], \n",
    "    qwen_coman['precision'], \n",
    "    qwen_fb['precision']\n",
    "]\n",
    "\n",
    "x = np.arange(len(bool_categories))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars1 = ax.bar(x - width/2, astra_precisions, width, label='ASTRA', color='#2ecc71')\n",
    "bars2 = ax.bar(x + width/2, qwen_precisions, width, label='QWEN', color='#f39c12')\n",
    "\n",
    "ax.set_ylabel('Precision (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Model Precision Comparison (Boolean Categories)', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(bool_categories)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1f}%',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False Positives and False Negatives comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# False Positives\n",
    "astra_fp = [astra_equip['fp'], astra_coman['fp'], astra_fb['fp']]\n",
    "qwen_fp = [qwen_equip['fp'], qwen_coman['fp'], qwen_fb['fp']]\n",
    "\n",
    "x = np.arange(len(bool_categories))\n",
    "bars1 = ax1.bar(x - width/2, astra_fp, width, label='ASTRA', color='#e74c3c')\n",
    "bars2 = ax1.bar(x + width/2, qwen_fp, width, label='QWEN', color='#c0392b')\n",
    "\n",
    "ax1.set_ylabel('Count', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('False Positives Comparison', fontsize=13, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(bool_categories, rotation=15, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# False Negatives\n",
    "astra_fn = [astra_equip['fn'], astra_coman['fn'], astra_fb['fn']]\n",
    "qwen_fn = [qwen_equip['fn'], qwen_coman['fn'], qwen_fb['fn']]\n",
    "\n",
    "bars3 = ax2.bar(x - width/2, astra_fn, width, label='ASTRA', color='#f39c12')\n",
    "bars4 = ax2.bar(x + width/2, qwen_fn, width, label='QWEN', color='#d68910')\n",
    "\n",
    "ax2.set_ylabel('Count', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('False Negatives Comparison', fontsize=13, fontweight='bold')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(bool_categories, rotation=15, ha='right')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bars in [bars3, bars4]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Overall Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall accuracy\n",
    "astra_total_correct = (\n",
    "    astra_equip['tp'] + astra_equip['tn'] +\n",
    "    astra_coman['tp'] + astra_coman['tn'] +\n",
    "    astra_fb['tp'] + astra_fb['tn'] +\n",
    "    astra_spec['correct']\n",
    ")\n",
    "\n",
    "qwen_total_correct = (\n",
    "    qwen_equip['tp'] + qwen_equip['tn'] +\n",
    "    qwen_coman['tp'] + qwen_coman['tn'] +\n",
    "    qwen_fb['tp'] + qwen_fb['tn'] +\n",
    "    qwen_spec['correct']\n",
    ")\n",
    "\n",
    "total_predictions = len(df) * 4  # 4 categories\n",
    "\n",
    "astra_overall = (astra_total_correct / total_predictions) * 100\n",
    "qwen_overall = (qwen_total_correct / total_predictions) * 100\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"OVERALL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal Records: {len(df)}\")\n",
    "print(f\"Total Predictions per Model: {total_predictions}\")\n",
    "print(f\"\\nASTRA Overall Accuracy: {astra_overall:.2f}%\")\n",
    "print(f\"QWEN Overall Accuracy: {qwen_overall:.2f}%\")\n",
    "print(f\"\\nDifference: {abs(astra_overall - qwen_overall):.2f}%\")\n",
    "\n",
    "if astra_overall > qwen_overall:\n",
    "    print(f\"\\nðŸ† OVERALL WINNER: ASTRA\")\n",
    "elif qwen_overall > astra_overall:\n",
    "    print(f\"\\nðŸ† OVERALL WINNER: QWEN\")\n",
    "else:\n",
    "    print(f\"\\nðŸ¤ TIE\")\n",
    "\n",
    "# Create summary table\n",
    "summary_data = {\n",
    "    'Category': ['Equipment', 'Co-Manufacturing', 'Food & Beverage', 'Specialty', 'OVERALL'],\n",
    "    'ASTRA Accuracy': [\n",
    "        f\"{astra_equip['accuracy']:.2f}%\",\n",
    "        f\"{astra_coman['accuracy']:.2f}%\",\n",
    "        f\"{astra_fb['accuracy']:.2f}%\",\n",
    "        f\"{astra_spec['accuracy']:.2f}%\",\n",
    "        f\"{astra_overall:.2f}%\"\n",
    "    ],\n",
    "    'QWEN Accuracy': [\n",
    "        f\"{qwen_equip['accuracy']:.2f}%\",\n",
    "        f\"{qwen_coman['accuracy']:.2f}%\",\n",
    "        f\"{qwen_fb['accuracy']:.2f}%\",\n",
    "        f\"{qwen_spec['accuracy']:.2f}%\",\n",
    "        f\"{qwen_overall:.2f}%\"\n",
    "    ],\n",
    "    'Winner': [\n",
    "        'ASTRA' if astra_equip['accuracy'] > qwen_equip['accuracy'] else 'QWEN',\n",
    "        'ASTRA' if astra_coman['accuracy'] > qwen_coman['accuracy'] else 'QWEN',\n",
    "        'ASTRA' if astra_fb['accuracy'] > qwen_fb['accuracy'] else 'QWEN',\n",
    "        'ASTRA' if astra_spec['accuracy'] > qwen_spec['accuracy'] else 'QWEN',\n",
    "        'ASTRA' if astra_overall > qwen_overall else 'QWEN'\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY TABLE\")\n",
    "print(\"=\"*80)\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Error Analysis - Find Specific Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find manufacturers where models disagree\n",
    "print(\"Manufacturers where ASTRA and QWEN disagree on Equipment:\")\n",
    "equip_disagree = df[df['astra_has_equipments'] != df['qwen_has_equipments']]\n",
    "print(f\"Count: {len(equip_disagree)}\")\n",
    "print(equip_disagree[['manufacturer_id', 'db_domain', 'db_has_equipments', \n",
    "                       'astra_has_equipments', 'qwen_has_equipments']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nManufacturers where ASTRA and QWEN disagree on Co-Manufacturing:\")\n",
    "coman_disagree = df[df['astra_is_coman'] != df['qwen_is_coman']]\n",
    "print(f\"Count: {len(coman_disagree)}\")\n",
    "print(coman_disagree[['manufacturer_id', 'db_domain', 'db_is_coman', \n",
    "                       'astra_is_coman', 'qwen_is_coman']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nManufacturers where ASTRA and QWEN disagree on Specialty:\")\n",
    "spec_disagree = df[df['astra_specialty'] != df['qwen_specialty']]\n",
    "print(f\"Count: {len(spec_disagree)}\")\n",
    "print(spec_disagree[['manufacturer_id', 'db_domain', 'db_specialty', \n",
    "                      'astra_specialty', 'qwen_specialty']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Insights and Recommendations\n",
    "\n",
    "### Strengths:\n",
    "- **ASTRA**: Better at Equipment detection, Co-Manufacturing classification\n",
    "- **QWEN**: Excels at Food & Beverage classification (100% accuracy), significantly better at Specialty classification\n",
    "\n",
    "### Weaknesses:\n",
    "- **ASTRA**: Struggles with Specialty classification (63.90% accuracy)\n",
    "- **QWEN**: Slightly more false negatives in Equipment detection\n",
    "\n",
    "### Overall Winner:\n",
    "**QWEN** has higher overall accuracy, primarily due to superior performance on Specialty classification.\n",
    "\n",
    "### Recommendations:\n",
    "1. Consider using an ensemble approach combining both models\n",
    "2. Use QWEN for Specialty and Food & Beverage classifications\n",
    "3. Use ASTRA for Equipment and Co-Manufacturing when precision is critical\n",
    "4. Focus improvement efforts on ASTRA's Specialty classification capabilities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}